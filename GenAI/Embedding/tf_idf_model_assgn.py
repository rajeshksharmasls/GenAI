# -*- coding: utf-8 -*-
"""TF-IDF_Model_Assgn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d6yA0Xdfsk0vXOJqrtIiTltLZbiVFcpR
"""



"""## Term Frequency – Inverse Document Frequency(TF-IDF) - Word Embedding Model"""

# Importing all the necessary libraries
import numpy as np                                          # For numerical operations
import pandas as pd                                         # For data manipulation and analysis
import matplotlib.pyplot as plt                             # For data visualization
import altair as alt                                        # For data visualization (used for creating charts and graphs)
import glob                                                 # For finding files and directories that match a specified pattern
from sklearn.feature_extraction.text import CountVectorizer # To convert the text data into a word count vector
from sklearn.feature_extraction.text import TfidfVectorizer # To convert the text data into a TF-IDF vector
from pathlib import Path                                    # For handling filesystem paths in a more object-oriented way

# Set pandas to display more rows for large DataFrames
pd.set_option('display.max_rows', 600)

# Define the directory where the text files are stored
directory_path = "/content/US_Inaugural_Addresses"

# Retrieve a list of all text files in the specified directory
text_files = glob.glob(f"{directory_path}/*.txt")    # Define the directory where the text files are stored

# Print the list of file names
text_files

# Extract the file names without extensions to use as document titles
text_titles = [Path(text).stem for text in text_files]

text_titles

# Initialize the TF-IDF Vectorizer with stop words in English
tfidf_vectorizer = TfidfVectorizer(input='filename', stop_words='english')

# Apply the TF-IDF vectorizer to the list of text files, resulting in a sparse matrix
tfidf_vector = tfidf_vectorizer.fit_transform(text_files)

# Convert the TF-IDF matrix to a DataFrame for easier manipulation
tfidf_df = pd.DataFrame(tfidf_vector.toarray(), index=text_titles, columns=tfidf_vectorizer.get_feature_names_out())

# Output: A DataFrame where each row represents a document and each column represents a term with its TF-IDF score.
# Example: Rows labeled with document titles (e.g., 'washington_1789') and columns with terms like 'government', 'people', etc.

# Add a new row to calculate the document frequency of each term (how many documents contain the term)
tfidf_df.loc['00_Document Frequency'] = (tfidf_df > 0).sum()

# Extract a slice of the DataFrame for specific terms of interest
tfidf_slice = tfidf_df[['government', 'borders', 'people', 'obama', 'war', 'honor', 'foreign', 'men', 'women', 'children']]

# Output: A smaller DataFrame showing TF-IDF scores for selected terms across documents.
# Example: TF-IDF scores for terms like 'government', 'people', etc., across different inaugural addresses.

# Sort the DataFrame by the index (document titles) and round TF-IDF scores to two decimal places
tfidf_slice.sort_index().round(decimals=2)

# Remove the '00_Document Frequency' row from the original DataFrame
tfidf_df = tfidf_df.drop('00_Document Frequency', errors='ignore')

# Stack the DataFrame to convert it from a wide format to a long format
tfidf_df = tfidf_df.stack().reset_index()

# Output: A long DataFrame where each row contains a document, a term, and the corresponding TF-IDF score.
# Example: Columns 'document', 'term', 'tfidf'.

# Rename the columns to make them more meaningful
tfidf_df = tfidf_df.rename(columns={0: 'tfidf', 'level_0': 'document', 'level_1': 'term', 'level_2': 'term'})

# Sort the DataFrame by document and TF-IDF score, then group by document and keep the top 10 terms for each document
top_tfidf = tfidf_df.sort_values(by=['document', 'tfidf'], ascending=[True, False]).groupby(['document']).head(10)

# Output: A DataFrame with the top 10 terms (by TF-IDF score) for each document.
# Example: Top terms for 'washington_1789', 'obama_2009', etc.

# Filter the DataFrame to find the top terms containing the word 'women'
top_tfidf[top_tfidf['term'].str.contains('women')]

# Output: Rows in the DataFrame where the term is 'women'.
# Example: TF-IDF scores for the term 'women' across different documents.

# Filter the DataFrame to find the top terms for documents containing 'obama' in their title
top_tfidf[top_tfidf['document'].str.contains('obama')]

# Output: Top terms for documents related to President Obama.
# Example: TF-IDF scores for terms in 'obama_2009', 'obama_2013', etc.

# Filter the DataFrame to find the top terms for documents containing 'trump' in their title
top_tfidf[top_tfidf['document'].str.contains('trump')]

# Output: Top terms for documents related to President Trump.
# Example: TF-IDF scores for terms in 'trump_2017', etc.

# Filter the DataFrame to find the top terms for documents containing 'kennedy' in their title
top_tfidf[top_tfidf['document'].str.contains('kennedy')]

# Output: Top terms for documents related to President Kennedy.
# Example: TF-IDF scores for terms in 'kennedy_1961', etc.

"""Heatmap"""

# Make a heatmap that shows the highest TF-IDF scoring words for each president
# Putting a red dot next to two terms of interest: “war” and “peace”

# Terms in this list will get a red dot in the visualization
term_list = ['war', 'peace']

# adding a little randomness to break ties in term ranking
top_tfidf_plusRand = top_tfidf.copy()
top_tfidf_plusRand['tfidf'] = top_tfidf_plusRand['tfidf'] + np.random.rand(top_tfidf.shape[0])*0.0001

# base for all visualizations, with rank calculation
base = alt.Chart(top_tfidf_plusRand).encode(
    x = 'rank:O',
    y = 'document:N'
).transform_window(
    rank = "rank()",
    sort = [alt.SortField("tfidf", order="descending")],
    groupby = ["document"],
)

# heatmap specification
heatmap = base.mark_rect().encode(
    color = 'tfidf:Q'
)

# red circle over terms in above list
circle = base.mark_circle(size=100).encode(
    color = alt.condition(
        alt.FieldOneOfPredicate(field='term', oneOf=term_list),
        alt.value('red'),
        alt.value('#FFFFFF00')
    )
)

# text labels, white for darker heatmap colors
text = base.mark_text(baseline='middle').encode(
    text = 'term:N',
    color = alt.condition(alt.datum.tfidf >= 0.23, alt.value('white'), alt.value('black'))
)

# display the three superimposed visualizations
(heatmap + circle + text).properties(width = 600)

# Heatmap shows the highest TF-IDF scoring words for each president, and puts a red dot next to
# two terms of interest: “war” and “peace"