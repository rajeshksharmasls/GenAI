# -*- coding: utf-8 -*-
"""FastText_Model_Assgn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xrkv2-Sp7c5tkPIxqx-maybwKRjkK0hG
"""



"""## FastText - Word Embedding Model"""

# Importing all the necessary libraries
from gensim.models.phrases import Phrases, Phraser                                         # To automatically detect common phrases (bigrams) from a list of sentences
from gensim.models import FastText                                                         # To train the FastText model
import pandas as pd                                                                        # For data handling

# Reading the file
df = pd.read_csv('/content/medical_dataset.csv')
print(df.head())

# Extract the familiar phrases from the dataset and the most meaningful n-grams, the Phrases model in the Gensim is used
sent = [row.split() for row in df['Text']]
phrases = Phrases(sent, min_count = 30, progress_per = 10000)
sentences = phrases[sent]

#Initializing the model
model = FastText(vector_size = 100, window = 5, min_count = 5, workers = 4, min_n = 1, max_n = 4)

#Building Vocabulary
model.build_vocab(sentences)
# print(len(model.wv.vocab.keys()))
print(len(model.wv.key_to_index.keys()))

#Training the model
model.train(sentences, total_examples = len(sentences), epochs=100)

# Saving the model
import joblib
path = 'FastText.joblib'
joblib.dump(model, path)

# Access embeddings
word_embeddings = model.wv
print(word_embeddings['subword'])

# Creating the vocabulary
vocabulary = model.wv.key_to_index.keys()

# Check whether word ‘python’ is present in the vocabulary
model.wv.most_similar("python", topn = 5)

# We can see the top 5 most similar words to ‘python.’

# Check word that is not in the vocabulary and try to find the most similar words
model.wv.most_similar("epidemic out-break", topn = 10)

# As we can see, fastText can provide embeddings for words not present in its vocabulary. In contrast, other word
# embedding models like word2vec and GloVe cannot provide embeddings for out-of-vocabulary words