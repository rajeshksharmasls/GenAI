# -*- coding: utf-8 -*-
"""ChatBot_Streamlit_OpenSourceLLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oljnAfInkzVbqHmuJv1qK4qZ2k5fRT0l

## Chatbot For Retail Industry
"""

# Importing the necessary libraries
from langchain_core.prompts import ChatPromptTemplate             # To structure prompts that interact with LLMs like Llama2
from langchain_community.llms import Ollama                       # Interface that allows you to use models like Llama2 for language generation tasks
import streamlit as st                                            # Open-source framework for building web apps using Python

# Define a prompt template for the chatbot
prompt=ChatPromptTemplate.from_messages(
    [
        ("system","You are a helpful assistant. Please response to the questions"),
        ("user","Question:{question}")
    ]
)

# Initialize the Ollama model
llm=Ollama(model="llama2")

# Create a chain that combines the prompt and the Ollama model
chain=prompt|llm

# Function to handle retail-specific inquiries
def get_retail_response(user_input):
    """
    This function processes the user input (prompt) and returns a retail-specific response.
    It includes predefined responses for common retail queries such as product availability,
    order status, promotions, store locations, and return policies.
    If the input doesn't match any predefined query, it defaults to llama for a generic response.
    """

     # Simple keyword-based matching to determine the user's query
    if "product" in user_input.lower() or "stock" in user_input.lower():
        # Response for product availability inquiries
        return "Sure! Which product would you like to check the availability for?"
    elif "order" in user_input.lower() or "status" in user_input.lower():
        # Response for order status inquiries
        return "Please provide your order number, and Iâ€™ll check the status for you."
    elif "promotion" in user_input.lower() or "discount" in user_input.lower():
        # Response for promotions or discount-related inquiries
        return "Today's promotions include 20% off on electronics and buy one get one free on selected clothing items."
    elif "store" in user_input.lower() or "location" in user_input.lower():
        # Response for store location-related inquiries
        return "Our nearest store is located at Main Street. Would you like directions?"
    elif "return" in user_input.lower() or "exchange" in user_input.lower():
        # Response for return or exchange policy inquiries
        return "Our return policy allows returns within 30 days with a receipt. Do you need assistance with a specific order?"
    else:
        # Default response using Llama2 for generic questions
        response = chain.invoke({"question": user_input})

        return response

# Set up the Streamlit framework
st.title("Retail Industry Chatbot (Llama2 with LangChain)")           # Set the title of the Streamlit app

# Input box for the user to type their message to the chatbot
user_input = st.text_input("Ask your question: ", "Hello, how can I assist you today?")

# Initialize a conversation history if it doesn't already exist in the session state
# This will keep track of the user's conversation with the chatbot
if "conversation" not in st.session_state:
    st.session_state.conversation = []

# Button to send the user's message to the chatbot
if st.button("Send"):
    if user_input:
        # Append the user's input to the conversation history
        st.session_state.conversation.append(f"You: {user_input}")

        # Get the chatbot's response based on the user's input
        response = get_retail_response(user_input)

        # Append the chatbot's response to the conversation history
        st.session_state.conversation.append(f"Chatbot: {response}")

# Display the conversation history on the Streamlit app
for message in st.session_state.conversation:
    st.write(message)