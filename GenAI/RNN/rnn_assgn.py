# -*- coding: utf-8 -*-
"""RNN_Assgn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u8rXwkQ1e9coFcSsL4N1PPwti37E4TWq
"""



"""## Recurrent Neural Network (RNN)"""

# Importing the necessary libraries
import pandas as pd									                                 ## For data manipulation and analysis
import numpy as np									                                 ## To handle numerical operations and arrays
import matplotlib.pyplot as plt								                       ## For data visualization
import seaborn as sns									                               ## For data visualization
from wordcloud import WordCloud								                       ## To create word cloud visualizations from text data
from sklearn.cluster import KMeans							                     ## For unsupervised learning using KMeans clustering
from sklearn.decomposition import PCA							                   ## Principal Component Analysis for dimensionality reduction
from sklearn.feature_extraction.text import TfidfVectorizer				   ## To convert text into numerical values based on TF-IDF for ML models
from sklearn.naive_bayes import MultinomialNB						             ## Used for text classification and problems with discrete data
from sklearn.linear_model import LogisticRegression					         ## Used for binary or multi-class classification
from sklearn.ensemble import RandomForestClassifier					         ## For creating multiple decision trees and merging them for better accuracy
from sklearn.tree import DecisionTreeClassifier						           ## For building a model in the form of a tree structure
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix	## Metrics for model evaluation
from sklearn.preprocessing import LabelEncoder						           ## For encoding categorical variables into numerical format
from keras.models import Sequential      						                 ## To build and train deep learning models
from keras.layers import SimpleRNN                                   ## To build and train RNN model
from keras.layers import Dense, Dropout  						                 ## To build and train deep learning models
from keras.utils import to_categorical							                 ## To build and train deep learning models
import nltk 										                                     ## Natural Language Toolkit, used for text preprocessing

"""Load the data and view the details"""

## Load the data
training_data = pd.read_csv('/content/twitter_training.csv')
validation_data = pd.read_csv('/content/twitter_validation.csv')

training_data.shape

validation_data.shape

training_data.dtypes

training_data.describe()

training_data.head()

validation_data.head()

"""Data Preprocessing"""

# Naming the columns
training_data.columns = ['ID', 'Entity', 'Sentiment', 'Message']
validation_data.columns = ['ID', 'Entity', 'Sentiment', 'Message']

# Checking for the duplicates
training_data.duplicated().sum()

# Drop the duplicate rows
training_data.drop_duplicates(inplace=True)

# Check for the missing values
training_data.isna().sum()

# Drop the rows with missing values
training_data.dropna(axis = 0 , inplace= True)

training_data.isna().sum()

training_data.shape

"""Data Visualization"""

# Sentiment Distribution in Training Data - Bar Graph
plt.figure(figsize=(8, 6))
sns.countplot(x='Sentiment', data=training_data)
plt.title('Sentiment Distribution in Training Data')
plt.show()

# Sentiment Distribution in Training Data - Pie Chart
sentiment_counts = training_data['Sentiment'].value_counts()

plt.figure(figsize=(8, 8))
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'])
plt.title('Sentiment Distribution in Training Data')
plt.show()

# Sentiment Distribution in Validation data - Bar Graph
plt.figure(figsize=(8, 6))
sns.countplot(x='Sentiment', data=validation_data)
plt.title('Sentiment Distribution in Validation Data')
plt.show()

# Sentiment Distribution in Validation Data - Pie Chart
sentiment_counts = validation_data['Sentiment'].value_counts()

plt.figure(figsize=(8, 8))
plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff','#99ff99','#ffcc99'])
plt.title('Sentiment Distribution in Validation Data')
plt.show()

# Frequency of All Entities in Training Data
entity_counts = training_data['Entity'].value_counts()

plt.figure(figsize=(10, len(entity_counts) / 2))
sns.barplot(y=entity_counts.index, x=entity_counts.values, orient='h')
plt.title('Frequency of All Entities in Training Data')
plt.xlabel('Count')
plt.ylabel('Entity')
plt.show()

# Stacked Bar Chart of Sentiment Distribution by Entity
entity_sentiment_counts = pd.crosstab(training_data['Entity'], training_data['Sentiment'])

plt.figure(figsize=(12, 8))
entity_sentiment_counts.plot(kind='bar', stacked=True, figsize=(12, 8))
plt.title('Stacked Bar Chart of Entity and Sentiments')
plt.xlabel('Entity')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Message Length Distribution
training_data['Message_Length'] = training_data['Message'].apply(len)
validation_data['Message_Length'] = validation_data['Message'].apply(len)

# Message Length Distribution in Training Data
plt.figure(figsize=(8, 6))
sns.histplot(training_data['Message_Length'], kde=True, bins=30)
plt.title('Message Length Distribution in Training Data')
plt.show()

# Message Length Distribution in Validation Data
plt.figure(figsize=(8, 6))
sns.histplot(validation_data['Message_Length'], kde=True, bins=30)
plt.title('Message Length Distribution in Validation Data')
plt.show()

"""Wordcloud"""

# Filter messages based on sentiment categories
positive_messages = ' '.join(training_data[training_data['Sentiment'] == 'Positive']['Message'])
negative_messages = ' '.join(training_data[training_data['Sentiment'] == 'Negative']['Message'])
neutral_messages = ' '.join(training_data[training_data['Sentiment'] == 'Neutral']['Message'])
irrelevant_messages = ' '.join(training_data[training_data['Sentiment'] == 'Irrelevant']['Message'])

# Create word clouds for each sentiment category
wordcloud_positive = WordCloud(width=800, height=400, background_color='white').generate(positive_messages)
wordcloud_negative = WordCloud(width=800, height=400, background_color='white').generate(negative_messages)
wordcloud_neutral = WordCloud(width=800, height=400, background_color='white').generate(neutral_messages)
wordcloud_irrelevant = WordCloud(width=800, height=400, background_color='white').generate(irrelevant_messages)

# Set up subplots to show all word clouds
plt.figure(figsize=(16, 12))

# Plot Positive WordCloud
plt.subplot(2, 2, 1)
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.title('Word Cloud for Positive Sentiment')
plt.axis('off')

# Plot Negative WordCloud
plt.subplot(2, 2, 2)
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.title('Word Cloud for Negative Sentiment')
plt.axis('off')

# Plot Neutral WordCloud
plt.subplot(2, 2, 3)
plt.imshow(wordcloud_neutral, interpolation='bilinear')
plt.title('Word Cloud for Neutral Sentiment')
plt.axis('off')

# Plot Irrelevant WordCloud
plt.subplot(2, 2, 4)
plt.imshow(wordcloud_irrelevant, interpolation='bilinear')
plt.title('Word Cloud for Irrelevant Sentiment')
plt.axis('off')

# Display the plots
plt.tight_layout()
plt.show()

"""TF-IDF Vectorization"""

# Preprocess the text using TF-IDF
tfidf_vectorizer = TfidfVectorizer(max_features=5000)

# Transform the training and validation messages
X_train_tfidf = tfidf_vectorizer.fit_transform(training_data['Message'])
X_validation_tfidf = tfidf_vectorizer.transform(validation_data['Message'])

# Target labels
y_train = training_data['Sentiment']
y_validation = validation_data['Sentiment']

"""K-Means++ Clustering"""

wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
    kmeans.fit(X_train_tfidf)
    wcss.append(kmeans.inertia_)

# Plot the WCSS
plt.figure(figsize=(8, 6))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Optimal Number of Clusters by Elbow Method')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Initialize the KMeans model
kmeans_model = KMeans(n_clusters=6, init='k-means++', random_state=42)

# Train the model
kmeans_model.fit(X_train_tfidf)

# Predict cluster labels for the validation set
cluster_labels = kmeans_model.predict(X_train_tfidf)

# Reduce the dimentionality of the data
pca = PCA(n_components=2)
X_train_pca = pca.fit_transform(X_train_tfidf.toarray())

# Plot the PCA result with cluster labels
plt.figure(figsize=(10, 6))
plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=cluster_labels, cmap='rainbow', s=50, alpha=0.7)
plt.title('KMeans++ Clustering of Validation Set (PCA Visualization)')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.show()

# Find the unique values in the array
np.unique(cluster_labels, return_counts=True)

"""Naive Bayes Classifier"""

nb_model = MultinomialNB()
nb_model.fit(X_train_tfidf, y_train)
y_pred_nb = nb_model.predict(X_validation_tfidf)

accuracy_nb = accuracy_score(y_validation, y_pred_nb)
report_nb = classification_report(y_validation, y_pred_nb)
print("Naive Bayes Accuracy:", accuracy_nb)
print("Naive Bayes Classification Report:\n", report_nb)

# Naive Bayes Accuracy is 70.8%

"""Logistic Regression"""

lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train_tfidf, y_train)
y_pred_lr = lr_model.predict(X_validation_tfidf)

accuracy_lr = accuracy_score(y_validation, y_pred_lr)
report_lr = classification_report(y_validation, y_pred_lr)
print("Logistic Regression Accuracy:", accuracy_lr)
print("Logistic Regression Classification Report:\n", report_lr)

# Logistic Regression Accuracy is 81.4% which is much  better than Naive Bayes

"""Random Forest"""

rf_model = RandomForestClassifier(n_estimators=100, max_depth= 100, random_state=42)
rf_model.fit(X_train_tfidf, y_train)
y_pred_rf = rf_model.predict(X_validation_tfidf)

accuracy_rf = accuracy_score(y_validation, y_pred_rf)
report_rf = classification_report(y_validation, y_pred_rf)
print("Random Forest Accuracy:", accuracy_rf)
print("Random Forest Classification Report:\n", report_rf)

# Random Forest Accuracy is 93.8% which is better than Logistic Regression as well.

"""Decision Tree"""

# Initialize the Decision Tree model
dt_model = DecisionTreeClassifier(random_state=42)

# Train the model
dt_model.fit(X_train_tfidf, y_train)

# Make predictions on the validation set
y_pred_dt = dt_model.predict(X_validation_tfidf)

# Evaluate the model
accuracy_dt = accuracy_score(y_validation, y_pred_dt)
report_dt = classification_report(y_validation, y_pred_dt)

# Classification Report
print("Decision Tree Model Accuracy:", accuracy_dt)
print("Decision Tree Model Classification Report:\n", report_dt)

# Decision Tree Accuracy is 87.8% which is better than Naives Bayes and Logistic Regression but worser than Random forest

"""RNN"""

# Encode Sentiments into numerical values
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_validation_encoded = encoder.transform(y_validation)

# One-hot encoding
y_train_categorical = to_categorical(y_train_encoded)
y_validation_categorical = to_categorical(y_validation_encoded)

# Reshape input to be 3D for RNN
# Assuming X_train_tfidf and X_validation_tfidf are 2D (samples, features)
# We add timesteps=1 because this is non-sequential data (or reshape it accordingly for sequences)
X_train_rnn = X_train_tfidf.toarray().reshape((X_train_tfidf.shape[0], 1, X_train_tfidf.shape[1]))
X_validation_rnn = X_validation_tfidf.toarray().reshape((X_validation_tfidf.shape[0], 1, X_validation_tfidf.shape[1]))

# Build the RNN model
model = Sequential()

# Add SimpleRNN layer
model.add(SimpleRNN(128, input_shape=(1, X_train_tfidf.shape[1]), activation='relu'))

# Add Dropout layer
model.add(Dropout(0.5))

# Add Dense layer
model.add(Dense(256, activation='relu'))

# Add another Dropout layer
model.add(Dropout(0.5))

# Output layer (for 4-class classification)
model.add(Dense(4, activation='softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model
history = model.fit(X_train_rnn, y_train_categorical, epochs=10, batch_size=64, validation_data=(X_validation_rnn, y_validation_categorical))

# Make predictions on the validation set
y_pred_rnn = model.predict(X_validation_rnn)
y_pred_rnn_labels = np.argmax(y_pred_rnn, axis=1)

# Decode the predicted labels
y_pred_labels_rnn = encoder.inverse_transform(y_pred_rnn_labels)

# Evaluate the model
accuracy_rnn = accuracy_score(y_validation, y_pred_labels_rnn)
report_rnn = classification_report(y_validation, y_pred_labels_rnn)

# Classification Report
print("RNN Model Accuracy:", accuracy_rnn)
print("RNN Model Classification Report:\n", report_rnn)

# RNN Model Accuracy is 967% which is best among all the models

# Plot the loss over epochs
plt.figure(figsize=(8, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Epoch vs Loss (RNN)')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

"""Optimize the RNN Model"""

# Encode Sentiments into numerical values
encoder = LabelEncoder()
y_train_encoded = encoder.fit_transform(y_train)
y_validation_encoded = encoder.transform(y_validation)

# One-hot encoding
y_train_categorical = to_categorical(y_train_encoded)
y_validation_categorical = to_categorical(y_validation_encoded)

# Reshape input to be 3D for RNN
# Assuming X_train_tfidf and X_validation_tfidf are 2D (samples, features)
# We add timesteps=1 to fit the input shape for RNN
X_train_rnn = X_train_tfidf.toarray().reshape((X_train_tfidf.shape[0], 1, X_train_tfidf.shape[1]))
X_validation_rnn = X_validation_tfidf.toarray().reshape((X_validation_tfidf.shape[0], 1, X_validation_tfidf.shape[1]))

# Build the RNN model with optimization techniques
optimized_model = Sequential()

# SimpleRNN layer with 128 units
optimized_model.add(SimpleRNN(128, input_shape=(X_train_rnn.shape[1], X_train_rnn.shape[2]), return_sequences=False))

# Add Dropout for regularization
optimized_model.add(Dropout(0.5))

# Add Dense hidden layer with 256 units
optimized_model.add(Dense(256, activation='relu'))

# Add another Dropout layer to prevent overfitting
optimized_model.add(Dropout(0.5))

# Output layer for multi-class classification (4 classes)
optimized_model.add(Dense(4, activation='softmax'))

# Compile the model with 'adam' optimizer
optimized_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the RNN model with the training data
history_rnn = optimized_model.fit(X_train_rnn, y_train_categorical, epochs=20, batch_size=32, validation_data=(X_validation_rnn, y_validation_categorical))

# Make predictions on the validation set
y_pred_rnn = optimized_model.predict(X_validation_rnn)
y_pred_rnn_labels = np.argmax(y_pred_rnn, axis=1)

# Decode the predicted labels back to original sentiments
y_pred_labels_rnn = encoder.inverse_transform(y_pred_rnn_labels)

# Evaluate the optimized RNN model's performance
accuracy_rnn = accuracy_score(y_validation, y_pred_labels_rnn)
report_rnn = classification_report(y_validation, y_pred_labels_rnn)

# Print the accuracy and classification report of the optimized RNN model
print("Optimized RNN Model Accuracy:", accuracy_rnn)
print("Optimized RNN Model Classification Report:\n", report_rnn)

# Plot accuracy over epochs
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history_rnn.history['accuracy'], label='Training Accuracy')
plt.plot(history_rnn.history['val_accuracy'], label='Validation Accuracy')
plt.title('RNN Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss over epochs
plt.subplot(1, 2, 2)
plt.plot(history_rnn.history['loss'], label='Training Loss')
plt.plot(history_rnn.history['val_loss'], label='Validation Loss')
plt.title('RNN Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# CONCLUSION: Optimized RNN accuracy is 94% which is less than the Vanilla RNN accuracy of 97%. Hence, its implied that the Vanilla RNN itself is already optimized.